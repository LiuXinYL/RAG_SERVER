#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å•å…ƒæµ‹è¯•ç”Ÿæˆå™¨
å®Œæ•´çš„Cä»£ç å•å…ƒæµ‹è¯•ç”Ÿæˆç³»ç»Ÿ
"""

import os
import sys
import json
import pandas as pd
from pathlib import Path
from typing import Dict, List, Any, Optional, Tuple
from dataclasses import dataclass
import logging

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.append(str(project_root))

# æ·»åŠ å½“å‰å·¥ä½œç›®å½•åˆ°è·¯å¾„
current_dir = Path.cwd()
sys.path.append(str(current_dir))

# å¯¼å…¥å¿…è¦çš„æ¨¡å—
try:
    # å°è¯•ä»é¡¹ç›®æ ¹ç›®å½•å¯¼å…¥
    sys.path.append(str(Path(__file__).parent.parent.parent))
    from llm_init import LLM_INIT
    from config import LLM_CONFIG
    LLM_AVAILABLE = True
except ImportError as e:
    LLM_AVAILABLE = False
    print(f"è­¦å‘Š: æ— æ³•å¯¼å…¥LLMæ¨¡å— - {e}")
    print("æç¤º: è¿™ä¸ä¼šå½±å“æ ¸å¿ƒåŠŸèƒ½ï¼Œä½†LLMç›¸å…³åŠŸèƒ½å°†è¢«ç¦ç”¨")

try:
    # å°è¯•å¤šç§å¯¼å…¥æ–¹å¼
    try:
        from test_software_platform.QAC.enhanced_c_parser import EnhancedCParser
        ENHANCED_PARSER_AVAILABLE = True
    except ImportError:
        # å°è¯•ç›¸å¯¹å¯¼å…¥
        sys.path.append(str(Path(__file__).parent.parent))
        from QAC.enhanced_c_parser import EnhancedCParser
        ENHANCED_PARSER_AVAILABLE = True
except ImportError as e:
    ENHANCED_PARSER_AVAILABLE = False
    print(f"è­¦å‘Š: æ— æ³•å¯¼å…¥å¢å¼ºç‰ˆCè§£æå™¨ - {e}")
    print("æç¤º: å°†ä½¿ç”¨åŸºç¡€è§£æåŠŸèƒ½")

# åœ¨å¯¼å…¥éƒ¨åˆ†æ·»åŠ promptç®¡ç†å™¨çš„å¯¼å…¥
try:
    from .prompt_manager import UnitTestPromptManager
    PROMPT_MANAGER_AVAILABLE = True
except ImportError:
    try:
        from prompt_manager import UnitTestPromptManager
        PROMPT_MANAGER_AVAILABLE = True
    except ImportError as e:
        PROMPT_MANAGER_AVAILABLE = False
        print(f"è­¦å‘Š: æ— æ³•å¯¼å…¥å•å…ƒæµ‹è¯•Promptç®¡ç†å™¨ - {e}")
        print("æç¤º: å°†ä½¿ç”¨é»˜è®¤promptæ„å»ºé€»è¾‘")

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

@dataclass
class TestCase:
    """æµ‹è¯•ç”¨ä¾‹æ•°æ®ç»“æ„"""
    test_name: str
    input_values: Dict[str, Any]
    expected_output: Any
    description: str
    test_id: str = ""
    boundary_type: str = "normal"  # normal, boundary, edge_case
    coverage_target: str = ""
    priority: str = ""

class FilePairMatcher:
    """æ–‡ä»¶å¯¹åŒ¹é…å™¨"""
    
    @staticmethod
    def find_matching_files(base_name: str, code_dir: str, excel_dir: str) -> Tuple[Optional[str], Optional[str]]:
        """
        ç¬¬ä¸€æ­¥ï¼šåˆ¤æ–­Cæ–‡ä»¶å’ŒExcelæ–‡ä»¶æ˜¯å¦ä¸ºåå­—ç»Ÿä¸€çš„æ–‡ä»¶å¯¹
        
        Args:
            base_name: åŸºç¡€æ–‡ä»¶åï¼ˆä¸å«æ‰©å±•åï¼‰
            code_dir: Cä»£ç ç›®å½•
            excel_dir: Excelæ–‡ä»¶ç›®å½•
            
        Returns:
            (c_file_path, excel_file_path) å…ƒç»„
        """
        code_path = Path(code_dir)
        excel_path = Path(excel_dir)
        
        # æŸ¥æ‰¾Cæ–‡ä»¶
        c_file = code_path / f"{base_name}.c"
        if not c_file.exists():
            logger.error(f"æ‰¾ä¸åˆ°Cæ–‡ä»¶: {c_file}")
            return None, None
        
        # å°è¯•å¤šç§å¯èƒ½çš„Excelæ–‡ä»¶å
        possible_excel_names = [
            f"{base_name}.xlsx",
            f"{base_name.replace('_', '').replace('-', '')}.xlsx",
            f"{base_name.replace('val', 'value')}.xlsx",
            f"{base_name.replace('value', 'val')}.xlsx",
            f"{base_name}_test.xlsx",
            f"{base_name}_cases.xlsx"
        ]
        
        excel_file = None
        for excel_name in possible_excel_names:
            temp_excel_file = excel_path / excel_name
            if temp_excel_file.exists():
                excel_file = temp_excel_file
                break
        
        if excel_file is None:
            logger.warning(f"æ‰¾ä¸åˆ°å¯¹åº”çš„Excelæ–‡ä»¶ï¼Œå°è¯•äº†: {possible_excel_names}")
            return str(c_file), None
        
        logger.info(f"æ‰¾åˆ°åŒ¹é…çš„æ–‡ä»¶å¯¹:")
        logger.info(f"  Cæ–‡ä»¶: {c_file}")
        logger.info(f"  Excelæ–‡ä»¶: {excel_file}")
        
        return str(c_file), str(excel_file)
    
    @staticmethod
    def find_folder_pairs(code_dir: str, excel_dir: str) -> List[Tuple[str, str, str]]:
        """
        æŸ¥æ‰¾æ–‡ä»¶å¤¹å¯¹ï¼Œæ¯ä¸ªæ–‡ä»¶å¤¹åŒ…å«ä¸€ç»„æµ‹è¯•æ•°æ®
        
        Args:
            code_dir: Cä»£ç æ ¹ç›®å½•
            excel_dir: Excelæ–‡ä»¶æ ¹ç›®å½•
            
        Returns:
            æ–‡ä»¶å¤¹å¯¹åˆ—è¡¨ï¼Œæ¯ä¸ªå…ƒç´ ä¸º (folder_name, code_folder_path, excel_folder_path)
        """
        code_path = Path(code_dir)
        excel_path = Path(excel_dir)
        
        if not code_path.exists():
            logger.error(f"Cä»£ç ç›®å½•ä¸å­˜åœ¨: {code_path}")
            return []
        
        if not excel_path.exists():
            logger.error(f"Excelç›®å½•ä¸å­˜åœ¨: {excel_path}")
            return []
        
        # è·å–codeç›®å½•ä¸‹çš„æ‰€æœ‰å­æ–‡ä»¶å¤¹
        code_folders = [f for f in code_path.iterdir() if f.is_dir()]
        logger.info(f"åœ¨Cä»£ç ç›®å½•ä¸­å‘ç° {len(code_folders)} ä¸ªæ–‡ä»¶å¤¹")
        
        folder_pairs = []
        
        for code_folder in code_folders:
            folder_name = code_folder.name
            
            # æŸ¥æ‰¾å¯¹åº”çš„Excelæ–‡ä»¶å¤¹
            excel_folder = excel_path / folder_name
            if excel_folder.exists():
                folder_pairs.append((folder_name, str(code_folder), str(excel_folder)))
                logger.info(f"æ‰¾åˆ°æ–‡ä»¶å¤¹å¯¹: {folder_name}")
            else:
                logger.warning(f"æ‰¾ä¸åˆ°å¯¹åº”çš„Excelæ–‡ä»¶å¤¹: {excel_folder}")
        
        logger.info(f"æ€»å…±æ‰¾åˆ° {len(folder_pairs)} ä¸ªæ–‡ä»¶å¤¹å¯¹")
        return folder_pairs
    
    @staticmethod
    def find_files_in_folder(code_folder: str, excel_folder: str) -> List[Tuple[str, str, str]]:
        """
        åœ¨æ–‡ä»¶å¤¹å¯¹ä¸­æŸ¥æ‰¾æ‰€æœ‰åŒ¹é…çš„æ–‡ä»¶å¯¹
        
        Args:
            code_folder: Cä»£ç æ–‡ä»¶å¤¹è·¯å¾„
            excel_folder: Excelæ–‡ä»¶å¤¹è·¯å¾„
            
        Returns:
            æ–‡ä»¶å¯¹åˆ—è¡¨ï¼Œæ¯ä¸ªå…ƒç´ ä¸º (base_name, c_file_path, excel_file_path)
        """
        code_path = Path(code_folder)
        excel_path = Path(excel_folder)
        
        if not code_path.exists():
            logger.error(f"Cä»£ç æ–‡ä»¶å¤¹ä¸å­˜åœ¨: {code_path}")
            return []
        
        if not excel_path.exists():
            logger.error(f"Excelæ–‡ä»¶å¤¹ä¸å­˜åœ¨: {excel_path}")
            return []
        
        # æŸ¥æ‰¾æ‰€æœ‰Cæ–‡ä»¶
        c_files = list(code_path.glob("*.c")) + list(code_path.glob("*.h"))
        logger.info(f"åœ¨Cä»£ç æ–‡ä»¶å¤¹ä¸­å‘ç° {len(c_files)} ä¸ªæ–‡ä»¶")
        
        file_pairs = []
        
        for c_file in c_files:
            base_name = c_file.stem
            
            # å°è¯•å¤šç§å¯èƒ½çš„Excelæ–‡ä»¶å
            possible_excel_names = [
                f"{base_name}.xlsx",
                f"{base_name.replace('_', '').replace('-', '')}.xlsx",
                f"{base_name.replace('val', 'value')}.xlsx",
                f"{base_name.replace('value', 'val')}.xlsx",
                f"{base_name}_test.xlsx",
                f"{base_name}_cases.xlsx"
            ]
            
            excel_file = None
            for excel_name in possible_excel_names:
                temp_excel_file = excel_path / excel_name
                if temp_excel_file.exists():
                    excel_file = temp_excel_file
                    break
            
            if excel_file:
                file_pairs.append((base_name, str(c_file), str(excel_file)))
                logger.info(f"æ‰¾åˆ°æ–‡ä»¶å¯¹: {base_name}")
            else:
                logger.warning(f"æ‰¾ä¸åˆ°å¯¹åº”çš„Excelæ–‡ä»¶: {base_name}")
        
        logger.info(f"åœ¨æ–‡ä»¶å¤¹å¯¹ä¸­æ‰¾åˆ° {len(file_pairs)} ä¸ªæ–‡ä»¶å¯¹")
        return file_pairs

class CCodeAnalyzer:
    """Cä»£ç åˆ†æå™¨"""
    
    def __init__(self):
        self.parser_available = ENHANCED_PARSER_AVAILABLE
    
    def analyze_folder(self, code_folder: str, output_dir: str) -> Dict[str, Any]:
        """
        ç¬¬ä¸€æ­¥ï¼šä½¿ç”¨enhanced_c_parser.pyè§£ææ–‡ä»¶å¤¹ä¸‹çš„æ‰€æœ‰Cæ–‡ä»¶å’ŒHæ–‡ä»¶
        
        Args:
            code_folder: Cä»£ç æ–‡ä»¶å¤¹è·¯å¾„
            output_dir: è¾“å‡ºç›®å½•
            
        Returns:
            è§£æç»“æœå­—å…¸
        """
        logger.info(f"å¼€å§‹è§£ææ–‡ä»¶å¤¹: {code_folder}")
        
        if not self.parser_available:
            logger.error("å¢å¼ºç‰ˆCè§£æå™¨ä¸å¯ç”¨")
            return {}
        
        try:
            # åˆ›å»ºè¾“å‡ºç›®å½•
            output_path = Path(output_dir)
            output_path.mkdir(parents=True, exist_ok=True)
            
            # åˆ›å»ºcode_info_jsonç›®å½•
            code_info_dir = Path("code_info_json")
            code_info_dir.mkdir(exist_ok=True)
            
            # æŸ¥æ‰¾æ‰€æœ‰Cå’ŒHæ–‡ä»¶
            code_path = Path(code_folder)
            c_files = list(code_path.glob("*.c")) + list(code_path.glob("*.h"))
            
            if not c_files:
                logger.error(f"åœ¨æ–‡ä»¶å¤¹ {code_folder} ä¸­æ‰¾ä¸åˆ°Cæˆ–Hæ–‡ä»¶")
                return {}
            
            logger.info(f"æ‰¾åˆ° {len(c_files)} ä¸ªC/Hæ–‡ä»¶")
            
            all_functions = []
            folder_name = code_path.name
            
            # è§£ææ¯ä¸ªæ–‡ä»¶
            for c_file in c_files:
                logger.info(f"è§£ææ–‡ä»¶: {c_file.name}")
                
                # åˆ›å»ºè§£æå™¨å®ä¾‹
                parser = EnhancedCParser(
                    code_dir=str(c_file.parent),
                    output_dir=str(output_path),
                    timeout=30
                )
                
                # è§£æå•ä¸ªæ–‡ä»¶
                success = parser.parse_single_file(c_file)
                
                if success:
                    # è¯»å–è§£æç»“æœ
                    safe_suffix = c_file.suffix.replace('.', '_')
                    result_file = output_path / f"{c_file.stem}{safe_suffix}_analysis.json"
                    
                    if result_file.exists():
                        with open(result_file, 'r', encoding='utf-8') as f:
                            file_analysis = json.load(f)
                        
                        # æå–å‡½æ•°ä¿¡æ¯
                        functions = file_analysis.get('functions', [])
                        for func in functions:
                            # æ·»åŠ æ–‡ä»¶ä¿¡æ¯
                            func['source_file'] = c_file.name
                            func['folder_name'] = folder_name
                            
                            # åˆ†æåˆ†æ”¯ä¿¡æ¯
                            func['branch_info'] = self._analyze_branches(func.get('body_content', ''))
                            
                        all_functions.extend(functions)
                        logger.info(f"ä»æ–‡ä»¶ {c_file.name} ä¸­æå–äº† {len(functions)} ä¸ªå‡½æ•°")
                    else:
                        logger.warning(f"è§£æå™¨æœªä¸ºæ–‡ä»¶ {c_file.name} ç”Ÿæˆç»“æœæ–‡ä»¶")
                else:
                    logger.warning(f"æ–‡ä»¶ {c_file.name} è§£æå¤±è´¥")
            
            # ä¿å­˜åˆå¹¶çš„è§£æç»“æœ
            combined_result = {
                'folder_name': folder_name,
                'source_folder': code_folder,
                'total_files': len(c_files),
                'total_functions': len(all_functions),
                'functions': all_functions,
                'analysis_timestamp': pd.Timestamp.now().isoformat()
            }
            
            # ä¿å­˜åˆ°code_info_jsonç›®å½•
            result_file = code_info_dir / f"{folder_name}_analysis.json"
            with open(result_file, 'w', encoding='utf-8') as f:
                json.dump(combined_result, f, ensure_ascii=False, indent=2)
            
            logger.info(f"æˆåŠŸè§£ææ–‡ä»¶å¤¹ {folder_name}ï¼Œå‘ç° {len(all_functions)} ä¸ªå‡½æ•°")
            return combined_result
                
        except Exception as e:
            logger.error(f"è§£ææ–‡ä»¶å¤¹æ—¶å‡ºé”™: {e}")
            return {}
    
    def _analyze_branches(self, function_body: str) -> Dict[str, Any]:
        """åˆ†æå‡½æ•°ä¸­çš„åˆ†æ”¯ä¿¡æ¯"""
        branch_info = {
            'if_statements': 0,
            'switch_statements': 0,
            'for_loops': 0,
            'while_loops': 0,
            'branch_coverage_target': 90  # ç›®æ ‡è¦†ç›–ç‡90%
        }
        
        try:
            # ç®€å•çš„åˆ†æ”¯ç»Ÿè®¡
            branch_info['if_statements'] = function_body.count('if (')
            branch_info['switch_statements'] = function_body.count('switch (')
            branch_info['for_loops'] = function_body.count('for (')
            branch_info['while_loops'] = function_body.count('while (')
            
            # è®¡ç®—æ€»åˆ†æ”¯æ•°
            total_branches = (branch_info['if_statements'] + 
                            branch_info['switch_statements'] + 
                            branch_info['for_loops'] + 
                            branch_info['while_loops'])
            
            branch_info['total_branches'] = total_branches
            
            # ä¼°ç®—éœ€è¦çš„æµ‹è¯•ç”¨ä¾‹æ•°ä»¥è¾¾åˆ°90%è¦†ç›–ç‡
            if total_branches > 0:
                branch_info['estimated_test_cases'] = max(3, int(total_branches * 1.5))
            else:
                branch_info['estimated_test_cases'] = 3
                
        except Exception as e:
            logger.warning(f"åˆ†æåˆ†æ”¯ä¿¡æ¯æ—¶å‡ºé”™: {e}")
        
        return branch_info
    
    def analyze_file(self, c_file_path: str, output_dir: str) -> Dict[str, Any]:
        """
        è§£æå•ä¸ªCæ–‡ä»¶ï¼ˆä¿æŒå‘åå…¼å®¹ï¼‰
        
        Args:
            c_file_path: Cæ–‡ä»¶è·¯å¾„
            output_dir: è¾“å‡ºç›®å½•
            
        Returns:
            è§£æç»“æœå­—å…¸
        """
        logger.info(f"å¼€å§‹è§£æCæ–‡ä»¶: {c_file_path}")
        
        if not self.parser_available:
            logger.info("å¢å¼ºç‰ˆCè§£æå™¨ä¸å¯ç”¨ï¼Œä½¿ç”¨åŸºç¡€è§£æåŠŸèƒ½")
            return self._basic_parse_c_file(c_file_path, output_dir)
        
        try:
            # åˆ›å»ºè¾“å‡ºç›®å½•
            output_path = Path(output_dir)
            output_path.mkdir(parents=True, exist_ok=True)
            
            # åˆ›å»ºè§£æå™¨å®ä¾‹
            parser = EnhancedCParser(
                code_dir=str(Path(c_file_path).parent),
                output_dir=str(output_path),
                timeout=30
            )
            
            # è§£æå•ä¸ªæ–‡ä»¶
            file_path_obj = Path(c_file_path)
            success = parser.parse_single_file(file_path_obj)
            
            if success:
                # è¯»å–è§£æç»“æœ
                safe_suffix = file_path_obj.suffix.replace('.', '_')
                result_file = output_path / f"{file_path_obj.stem}{safe_suffix}_analysis.json"
                
                if result_file.exists():
                    with open(result_file, 'r', encoding='utf-8') as f:
                        analysis_result = json.load(f)
                    
                    logger.info(f"æˆåŠŸè§£æCæ–‡ä»¶ï¼Œå‘ç° {len(analysis_result.get('functions', []))} ä¸ªå‡½æ•°")
                    return analysis_result
                else:
                    logger.error("è§£æå™¨æœªç”Ÿæˆç»“æœæ–‡ä»¶")
                    return self._basic_parse_c_file(c_file_path, output_dir)
            else:
                logger.error("Cæ–‡ä»¶è§£æå¤±è´¥ï¼Œä½¿ç”¨åŸºç¡€è§£æåŠŸèƒ½")
                return self._basic_parse_c_file(c_file_path, output_dir)
                
        except Exception as e:
            logger.error(f"è§£æCæ–‡ä»¶æ—¶å‡ºé”™: {e}")
            logger.info("å›é€€åˆ°åŸºç¡€è§£æåŠŸèƒ½")
            return self._basic_parse_c_file(c_file_path, output_dir)
    
    def _basic_parse_c_file(self, c_file_path: str, output_dir: str) -> Dict[str, Any]:
        """åŸºç¡€Cæ–‡ä»¶è§£æåŠŸèƒ½"""
        logger.info("ä½¿ç”¨åŸºç¡€Cæ–‡ä»¶è§£æåŠŸèƒ½")
        
        try:
            # è¯»å–Cæ–‡ä»¶å†…å®¹
            with open(c_file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            # ç®€å•çš„å‡½æ•°è§£æ
            functions = []
            
            # æŸ¥æ‰¾å‡½æ•°å®šä¹‰
            import re
            
            # åŒ¹é…å‡½æ•°å®šä¹‰çš„æ­£åˆ™è¡¨è¾¾å¼
            function_pattern = r'(\w+)\s+(\w+)\s*\([^)]*\)\s*\{'
            matches = re.finditer(function_pattern, content)
            
            for match in matches:
                return_type = match.group(1)
                function_name = match.group(2)
                
                # æå–å‡½æ•°ä½“
                start_pos = match.end()
                brace_count = 1
                end_pos = start_pos
                
                for i in range(start_pos, len(content)):
                    if content[i] == '{':
                        brace_count += 1
                    elif content[i] == '}':
                        brace_count -= 1
                        if brace_count == 0:
                            end_pos = i + 1
                            break
                
                function_body = content[start_pos:end_pos]
                
                # åˆ†æå‚æ•°ï¼ˆç®€åŒ–ç‰ˆæœ¬ï¼‰
                params_match = re.search(r'\(([^)]*)\)', match.group(0))
                parameters = []
                if params_match:
                    params_str = params_match.group(1).strip()
                    if params_str:
                        param_list = [p.strip() for p in params_str.split(',')]
                        for i, param in enumerate(param_list):
                            if param:
                                # ç®€å•çš„å‚æ•°è§£æ
                                param_parts = param.split()
                                if len(param_parts) >= 2:
                                    param_type = param_parts[0]
                                    param_name = param_parts[1]
                                    parameters.append({
                                        'name': param_name,
                                        'type': 'input',
                                        'index': i
                                    })
                
                # åˆ†æåˆ†æ”¯ä¿¡æ¯
                branch_info = self._analyze_branches(function_body)
                
                function_info = {
                    'name': function_name,
                    'return_type': return_type,
                    'parameters': parameters,
                    'body_content': function_body,
                    'source_file': Path(c_file_path).name,
                    'branch_info': branch_info
                }
                
                functions.append(function_info)
                logger.info(f"å‘ç°å‡½æ•°: {function_name}")
            
            analysis_result = {
                'functions': functions,
                'total_functions': len(functions),
                'source_file': c_file_path
            }
            
            logger.info(f"åŸºç¡€è§£æå®Œæˆï¼Œå‘ç° {len(functions)} ä¸ªå‡½æ•°")
            return analysis_result
            
        except Exception as e:
            logger.error(f"åŸºç¡€è§£æCæ–‡ä»¶æ—¶å‡ºé”™: {e}")
            return {'functions': [], 'total_functions': 0, 'source_file': c_file_path}

class ExcelDataProcessor:
    """Excelæ•°æ®å¤„ç†å™¨"""
    
    def __init__(self):
        self.properties_sheet = "Properties"
        self.values_sheet = "Values"
        self.description_field = "Description"
    

    def extract_function_parameters(self, values_data: List[Dict[str, Any]]) -> Dict[str, Any]:
        """ä»Valueså·¥ä½œè¡¨æå–å‡½æ•°å‚æ•°ä¿¡æ¯"""
        if not values_data:
            return {}
        
        # ç¬¬ä¸€è¡Œï¼šå‚æ•°åç§°
        param_names = []
        first_row = values_data[0] if values_data else {}
        
        for key, value in first_row.items():
            if key and key != 'nan' and str(value).strip():
                param_names.append(str(value))
        
        # ç¬¬äºŒè¡Œï¼ši/oç±»å‹
        io_types = []
        if len(values_data) > 1:
            second_row = values_data[1]
            for key, value in second_row.items():
                if key and key != 'nan' and str(value).strip():
                    io_types.append(str(value).lower())
        
        # æ„å»ºå‚æ•°ä¿¡æ¯
        parameters = []
        for i, (name, io_type) in enumerate(zip(param_names, io_types)):
            param_info = {
                'name': name,
                'type': 'input' if io_type == 'i' else 'output',
                'index': i
            }
            parameters.append(param_info)
        
        return {
            'parameters': parameters,
            'input_params': [p for p in parameters if p['type'] == 'input'],
            'output_params': [p for p in parameters if p['type'] == 'output']
        }
    
    
    def _parse_input_values(self, input_values_str: str) -> Dict[str, Any]:
        """è§£æè¾“å…¥å€¼å­—ç¬¦ä¸²"""
        try:
            if isinstance(input_values_str, str):
                return json.loads(input_values_str)
            elif isinstance(input_values_str, dict):
                return input_values_str
            else:
                return {}
        except Exception as e:
            logger.warning(f"è§£æè¾“å…¥å€¼æ—¶å‡ºé”™: {e}")
            return {}

class LLMTestGenerator:
    """å¤§æ¨¡å‹æµ‹è¯•ç”¨ä¾‹ç”Ÿæˆå™¨"""
    
    def __init__(self):
        self.llm_available = LLM_AVAILABLE
        self.llm_client = None
        self.prompt_manager = None
        
        if self.llm_available:
            try:
                # ç¬¬ä¸‰æ­¥ï¼šåˆå§‹åŒ–å¤§æ¨¡å‹
                self.llm_client = LLM_INIT(
                    max_tokens=LLM_CONFIG.get("max_tokens", 2000),
                    temperature=LLM_CONFIG.get("temperature", 0.7)
                ).create_chat_client()
                logger.info("å¤§æ¨¡å‹åˆå§‹åŒ–æˆåŠŸ")
            except Exception as e:
                logger.error(f"å¤§æ¨¡å‹åˆå§‹åŒ–å¤±è´¥: {e}")
                self.llm_available = False
        
        if PROMPT_MANAGER_AVAILABLE:
            try:
                self.prompt_manager = UnitTestPromptManager()
                logger.info("Promptç®¡ç†å™¨åˆå§‹åŒ–æˆåŠŸ")
            except Exception as e:
                logger.error(f"Promptç®¡ç†å™¨åˆå§‹åŒ–å¤±è´¥: {e}")
    
    def generate_test_cases(self, function_info: Dict[str, Any]) -> List[TestCase]:
        """
        ç¬¬äº”æ­¥ï¼šç”Ÿæˆæµ‹è¯•ç”¨ä¾‹ï¼Œé‡ç‚¹æµ‹è¯•ifåˆ†æ”¯ã€switchåˆ†æ”¯ï¼Œè¦†ç›–ç‡90%ä»¥ä¸Š
        
        Args:
            function_info: å‡½æ•°è¯¦ç»†ä¿¡æ¯
            function_properties: å‡½æ•°å±æ€§ä¿¡æ¯
            
        Returns:
            ç”Ÿæˆçš„æµ‹è¯•ç”¨ä¾‹åˆ—è¡¨
        """
        if not self.llm_available or not self.llm_client:
            logger.warning("å¤§æ¨¡å‹ä¸å¯ç”¨ï¼Œä½¿ç”¨æ¨¡æ‹Ÿæµ‹è¯•ç”¨ä¾‹")
            return self._generate_mock_test_cases(function_info)
        
        try:
            # è·å–åˆ†æ”¯ä¿¡æ¯
            branch_info = function_info.get('branch_info', {})
            target_coverage = branch_info.get('branch_coverage_target', 90)
            estimated_cases = branch_info.get('estimated_test_cases', 5)
            
            logger.info(f"ç›®æ ‡è¦†ç›–ç‡: {target_coverage}%")
            logger.info(f"ä¼°ç®—æµ‹è¯•ç”¨ä¾‹æ•°: {estimated_cases}")
            logger.info(f"åˆ†æ”¯ä¿¡æ¯: {branch_info}")
            
            # æ„å»ºprompt - ä½¿ç”¨æ–°çš„promptç®¡ç†å™¨
            if self.prompt_manager:
                try:
                    logger.info("ä½¿ç”¨promptç®¡ç†å™¨åˆ›å»ºç»¼åˆæµ‹è¯•prompt")
                    prompt = self.prompt_manager.create_comprehensive_test_prompt(
                        function_info=function_info,
                        branch_info=branch_info,
                    )
                except Exception as e:
                    logger.warning(f"ä½¿ç”¨promptç®¡ç†å™¨åˆ›å»ºpromptå¤±è´¥: {e}")
                    logger.info("å›é€€åˆ°é»˜è®¤promptæ„å»ºé€»è¾‘")
                    prompt = self._build_comprehensive_test_prompt(
                        function_info, branch_info
                    )
            else:
                logger.info("ä½¿ç”¨é»˜è®¤promptæ„å»ºé€»è¾‘")
                prompt = self._build_comprehensive_test_prompt(
                    function_info, branch_info
                )
            
            # è°ƒç”¨å¤§æ¨¡å‹ç”Ÿæˆæµ‹è¯•ç”¨ä¾‹
            from langchain_core.messages import HumanMessage, SystemMessage
            
            # ä½¿ç”¨prompt_managerä¸­çš„ç³»ç»Ÿprompt
            system_prompt = "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„Cä»£ç å•å…ƒæµ‹è¯•ç”Ÿæˆä¸“å®¶ï¼Œä¸“é—¨è´Ÿè´£ç”Ÿæˆé«˜è¦†ç›–ç‡çš„å•å…ƒæµ‹è¯•ç”¨ä¾‹ã€‚ä½ çš„æ ¸å¿ƒä»»åŠ¡æ˜¯åˆ†æCå‡½æ•°çš„ifåˆ†æ”¯å’Œswitchåˆ†æ”¯ï¼Œç”Ÿæˆèƒ½å¤Ÿè¾¾åˆ°90%ä»¥ä¸Šåˆ†æ”¯è¦†ç›–ç‡çš„æµ‹è¯•ç”¨ä¾‹ã€‚ä½ å…·å¤‡æ·±å…¥çš„ä»£ç åˆ†æèƒ½åŠ›ï¼Œèƒ½å¤Ÿè¯†åˆ«å…³é”®æ‰§è¡Œè·¯å¾„å’Œè¾¹ç•Œæ¡ä»¶ã€‚"
            if self.prompt_manager:
                try:
                    system_prompt = self.prompt_manager.get_system_prompt()
                    if not system_prompt:
                        system_prompt = "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„Cä»£ç å•å…ƒæµ‹è¯•ç”Ÿæˆä¸“å®¶ï¼Œä¸“é—¨è´Ÿè´£ç”Ÿæˆé«˜è¦†ç›–ç‡çš„å•å…ƒæµ‹è¯•ç”¨ä¾‹ã€‚ä½ çš„æ ¸å¿ƒä»»åŠ¡æ˜¯åˆ†æCå‡½æ•°çš„ifåˆ†æ”¯å’Œswitchåˆ†æ”¯ï¼Œç”Ÿæˆèƒ½å¤Ÿè¾¾åˆ°90%ä»¥ä¸Šåˆ†æ”¯è¦†ç›–ç‡çš„æµ‹è¯•ç”¨ä¾‹ã€‚ä½ å…·å¤‡æ·±å…¥çš„ä»£ç åˆ†æèƒ½åŠ›ï¼Œèƒ½å¤Ÿè¯†åˆ«å…³é”®æ‰§è¡Œè·¯å¾„å’Œè¾¹ç•Œæ¡ä»¶ã€‚"
                except Exception as e:
                    logger.warning(f"è·å–ç³»ç»Ÿpromptå¤±è´¥: {e}")
            
            messages = [
                SystemMessage(content=system_prompt),
                HumanMessage(content=prompt)
            ]

            logger.info(f"å¤§æ¨¡å‹ç”Ÿæˆæµ‹è¯•ç”¨ä¾‹")
            response = self.llm_client.invoke(messages)
            
            # å¤„ç†ä¸åŒçš„å“åº”æ ¼å¼
            response_content = self._extract_response_content(response)
            logger.info(f"å“åº”å†…å®¹é•¿åº¦: {len(response_content)} å­—ç¬¦")
            
            # è§£æå“åº”ç”Ÿæˆæµ‹è¯•ç”¨ä¾‹
            test_cases = self._parse_test_cases_response(response_content, function_info)
            
            # éªŒè¯è¦†ç›–ç‡
            coverage_analysis = self._analyze_test_coverage(test_cases, branch_info)
            logger.info(f"æµ‹è¯•è¦†ç›–ç‡åˆ†æ: {coverage_analysis}")
            
            logger.info(f"æˆåŠŸç”Ÿæˆ {len(test_cases)} ä¸ªæµ‹è¯•ç”¨ä¾‹")
            return test_cases
            
        except Exception as e:
            logger.error(f"ç”Ÿæˆæµ‹è¯•ç”¨ä¾‹æ—¶å‡ºé”™: {e}")
            return []
    
    def _build_comprehensive_test_prompt(self, function_info: Dict[str, Any],
                                       branch_info: Dict[str, Any]) -> str:
        """æ„å»ºå…¨é¢çš„æµ‹è¯•ç”¨ä¾‹ç”Ÿæˆprompt"""
        
        # ä¼˜å…ˆä½¿ç”¨promptç®¡ç†å™¨æ„å»ºprompt
        if self.prompt_manager:
            try:
                logger.info("ä½¿ç”¨promptç®¡ç†å™¨æ„å»ºå…¨é¢æµ‹è¯•ç”¨ä¾‹ç”Ÿæˆprompt")
                return self.prompt_manager.format_comprehensive_test_prompt(
                    function_name=function_info.get('name', 'unknown'),
                    return_type=function_info.get('return_type', 'unknown'),
                    parameters=function_info.get('parameters', []),
                    function_body=function_info.get('body_content', ''),
                    branch_info=branch_info,
                )
            except Exception as e:
                logger.warning(f"ä½¿ç”¨promptç®¡ç†å™¨æ„å»ºpromptå¤±è´¥: {e}")
                logger.info("å›é€€åˆ°é»˜è®¤promptæ„å»ºé€»è¾‘")
        
        # å›é€€åˆ°åŸæ¥çš„promptæ„å»ºé€»è¾‘
        logger.info("ä½¿ç”¨é»˜è®¤promptæ„å»ºé€»è¾‘")
        prompt_lines = []
        prompt_lines.append("## ğŸ¯ é«˜è¦†ç›–ç‡å•å…ƒæµ‹è¯•ç”Ÿæˆ")
        prompt_lines.append("")
        prompt_lines.append("### ğŸ“ ç›®æ ‡å‡½æ•°ä¿¡æ¯")
        prompt_lines.append(f"- **å‡½æ•°å**: {function_info.get('name', 'unknown')}")
        prompt_lines.append(f"- **è¿”å›ç±»å‹**: {function_info.get('return_type', 'unknown')}")
        prompt_lines.append(f"- **å‚æ•°åˆ—è¡¨**: {self._format_parameters(function_info.get('parameters', []))}")
        prompt_lines.append(f"- **æºæ–‡ä»¶**: {function_info.get('name', 'unknown')}.c")
        prompt_lines.append("")
        
        prompt_lines.append("### ğŸ’» å‡½æ•°ä»£ç è¯¦æƒ…")
        prompt_lines.append("#### å‡½æ•°ä½“:")
        prompt_lines.append(f"```c\n{function_info.get('body_content', '')}\n```")
        prompt_lines.append("")
        
        # åˆ†æ”¯ä¿¡æ¯
        if branch_info:
            prompt_lines.append("### ğŸ” åˆ†æ”¯åˆ†æä¿¡æ¯")
            prompt_lines.append("#### åˆ†æ”¯ç»Ÿè®¡:")
            prompt_lines.append(f"- **ifè¯­å¥æ•°é‡**: {branch_info.get('if_statements', 0)}")
            prompt_lines.append(f"- **switchè¯­å¥æ•°é‡**: {branch_info.get('switch_statements', 0)}")
            prompt_lines.append(f"- **forå¾ªç¯æ•°é‡**: {branch_info.get('for_loops', 0)}")
            prompt_lines.append(f"- **whileå¾ªç¯æ•°é‡**: {branch_info.get('while_loops', 0)}")
            prompt_lines.append(f"- **æ€»åˆ†æ”¯æ•°**: {branch_info.get('total_branches', 0)}")
            prompt_lines.append("- **ç›®æ ‡è¦†ç›–ç‡**: 90%+")
            prompt_lines.append(f"- **é¢„ä¼°æµ‹è¯•ç”¨ä¾‹æ•°**: {branch_info.get('estimated_test_cases', 5)}")
            prompt_lines.append("")
        
        # å‚æ•°ä¿¡æ¯
        parameters = function_info.get('parameters', [])
        input_parameters = []
        output_parameters = []
        
        for param in parameters:
            if param.get('type', '').lower() == 'input':
                input_parameters.append(f"- **{param.get('name', 'unknown')}**: {param.get('type', 'unknown')}")
            elif param.get('type', '').lower() == 'output':
                output_parameters.append(f"- **{param.get('name', 'unknown')}**: {param.get('type', 'unknown')}")
        
        input_params_str = '\n'.join(input_parameters) if input_parameters else "æ— è¾“å…¥å‚æ•°"
        output_params_str = '\n'.join(output_parameters) if output_parameters else "æ— è¾“å‡ºå‚æ•°"
        
        prompt_lines.append("### ğŸ“Š å‚æ•°ä¿¡æ¯")
        prompt_lines.append("#### è¾“å…¥å‚æ•° (i):")
        prompt_lines.append(input_params_str)
        prompt_lines.append("")
        prompt_lines.append("#### è¾“å‡ºå‚æ•° (o):")
        prompt_lines.append(output_params_str)
        prompt_lines.append("")
        
        # ç”Ÿæˆè¦æ±‚
        prompt_lines.append("### ğŸ¯ ç”Ÿæˆè¦æ±‚")
        prompt_lines.append("è¯·ç”Ÿæˆèƒ½å¤Ÿè¾¾åˆ°**90%ä»¥ä¸Šåˆ†æ”¯è¦†ç›–ç‡**çš„æµ‹è¯•ç”¨ä¾‹ï¼Œé‡ç‚¹å…³æ³¨ï¼š")
        prompt_lines.append("")
        prompt_lines.append("1. **ifåˆ†æ”¯æµ‹è¯•** - è¦†ç›–æ‰€æœ‰ifæ¡ä»¶çš„ä¸åŒåˆ†æ”¯")
        prompt_lines.append("   - æ¡ä»¶ä¸ºçœŸæ—¶çš„æ‰§è¡Œè·¯å¾„")
        prompt_lines.append("   - æ¡ä»¶ä¸ºå‡æ—¶çš„æ‰§è¡Œè·¯å¾„")
        prompt_lines.append("   - å¤åˆæ¡ä»¶çš„å„ç§ç»„åˆ")
        prompt_lines.append("")
        prompt_lines.append("2. **switchåˆ†æ”¯æµ‹è¯•** - è¦†ç›–æ‰€æœ‰caseåˆ†æ”¯")
        prompt_lines.append("   - æ¯ä¸ªcaseåˆ†æ”¯çš„æµ‹è¯•")
        prompt_lines.append("   - defaultåˆ†æ”¯çš„æµ‹è¯•")
        prompt_lines.append("   - è¾¹ç•Œcaseå€¼çš„æµ‹è¯•")
        prompt_lines.append("")
        prompt_lines.append("3. **è¾¹ç•Œå€¼æµ‹è¯•** - æµ‹è¯•è¾¹ç•Œæ¡ä»¶å’Œä¸´ç•Œå€¼")
        prompt_lines.append("   - å‚æ•°çš„æœ€å°å€¼ã€æœ€å¤§å€¼")
        prompt_lines.append("   - ä¸´ç•Œå€¼é™„è¿‘çš„æµ‹è¯•")
        prompt_lines.append("   - ç‰¹æ®Šå€¼ï¼ˆ0ã€-1ã€NULLç­‰ï¼‰")
        prompt_lines.append("")
        prompt_lines.append("4. **å¼‚å¸¸æƒ…å†µæµ‹è¯•** - æµ‹è¯•é”™è¯¯å¤„ç†è·¯å¾„")
        prompt_lines.append("   - æ— æ•ˆè¾“å…¥çš„å¤„ç†")
        prompt_lines.append("   - å¼‚å¸¸çŠ¶æ€çš„æ¢å¤")
        prompt_lines.append("   - é”™è¯¯è¿”å›å€¼çš„éªŒè¯")
        prompt_lines.append("")
        
        # è¾“å‡ºæ ¼å¼è¦æ±‚
        prompt_lines.append("### ğŸ“ è¾“å‡ºæ ¼å¼è¦æ±‚")
        prompt_lines.append("è¯·ä»¥JSONæ ¼å¼è¿”å›æµ‹è¯•ç”¨ä¾‹ï¼Œæ ¼å¼å¦‚ä¸‹ï¼š")
        prompt_lines.append("```json")
        prompt_lines.append("{")
        prompt_lines.append("  \"branch_coverage\": {")
        prompt_lines.append("    \"target_coverage\": 90,")
        prompt_lines.append("    \"estimated_coverage\": \"é¢„ä¼°è¦†ç›–ç‡ç™¾åˆ†æ¯”\",")
        prompt_lines.append("    \"critical_branches\": [\"å…³é”®åˆ†æ”¯åˆ—è¡¨\"],")
        prompt_lines.append("    \"coverage_strategy\": \"è¦†ç›–ç‡ç­–ç•¥è¯´æ˜\"")
        prompt_lines.append("  },")
        prompt_lines.append("  \"test_cases\": [")
        prompt_lines.append("    {")
        prompt_lines.append("      \"test_id\": \"å”¯ä¸€æµ‹è¯•ID\",")
        prompt_lines.append("      \"test_name\": \"æµ‹è¯•ç”¨ä¾‹åç§°\",")
        prompt_lines.append("      \"input_values\": {\"å‚æ•°å\": \"å‚æ•°å€¼\"},")
        prompt_lines.append("      \"expected_output\": \"æœŸæœ›è¾“å‡ºå€¼\",")
        prompt_lines.append("      \"description\": \"æµ‹è¯•æè¿°\",")
        prompt_lines.append("      \"branch_type\": \"if/switch/for/while\",")
        prompt_lines.append("      \"coverage_target\": \"è¦†ç›–çš„å…·ä½“åˆ†æ”¯\",")
        prompt_lines.append("      \"priority\": \"high/medium/low\"")
        prompt_lines.append("    }")
        prompt_lines.append("  ],")
        prompt_lines.append("  \"coverage_analysis\": {")
        prompt_lines.append("    \"if_branches_covered\": \"ifåˆ†æ”¯è¦†ç›–æƒ…å†µ\",")
        prompt_lines.append("    \"switch_branches_covered\": \"switchåˆ†æ”¯è¦†ç›–æƒ…å†µ\",")
        prompt_lines.append("    \"total_branches_covered\": \"æ€»åˆ†æ”¯è¦†ç›–æƒ…å†µ\",")
        prompt_lines.append("    \"coverage_gaps\": [\"è¦†ç›–ç‡ç¼ºå£\"],")
        prompt_lines.append("    \"additional_cases_needed\": \"æ˜¯å¦éœ€è¦é¢å¤–æµ‹è¯•ç”¨ä¾‹\"")
        prompt_lines.append("  }")
        prompt_lines.append("}")
        prompt_lines.append("```")
        prompt_lines.append("")
        
        # è´¨é‡æ ‡å‡†
        prompt_lines.append("### âœ… è´¨é‡æ ‡å‡†")
        prompt_lines.append("- **è¦†ç›–ç‡è¦æ±‚**: ç¡®ä¿90%ä»¥ä¸Šçš„åˆ†æ”¯è¦†ç›–ç‡")
        prompt_lines.append("- **åˆ†æ”¯å®Œæ•´æ€§**: è¦†ç›–æ‰€æœ‰ifå’Œswitchåˆ†æ”¯")
        prompt_lines.append("- **è¾¹ç•Œå®Œæ•´æ€§**: åŒ…å«æ‰€æœ‰è¾¹ç•Œæ¡ä»¶æµ‹è¯•")
        prompt_lines.append("- **å¯æ‰§è¡Œæ€§**: ç”Ÿæˆçš„æµ‹è¯•ç”¨ä¾‹å¯ä»¥ç›´æ¥æ‰§è¡Œ")
        prompt_lines.append("- **å¯éªŒè¯æ€§**: æœŸæœ›è¾“å‡ºå¿…é¡»å‡†ç¡®ä¸”å¯éªŒè¯")
        
        return "\n".join(prompt_lines)
    
    def _analyze_test_coverage(self, test_cases: List[TestCase], branch_info: Dict[str, Any]) -> Dict[str, Any]:
        """åˆ†ææµ‹è¯•ç”¨ä¾‹çš„è¦†ç›–ç‡"""
        coverage_analysis = {
            'total_test_cases': len(test_cases),
            'total_branches': branch_info.get('total_branches', 0),
            'estimated_coverage': 0,
            'coverage_details': {}
        }
        
        if branch_info.get('total_branches', 0) > 0:
            # ç®€å•ä¼°ç®—è¦†ç›–ç‡
            estimated_coverage = min(95, len(test_cases) * 15)  # æ¯ä¸ªæµ‹è¯•ç”¨ä¾‹çº¦è¦†ç›–15%çš„åˆ†æ”¯
            coverage_analysis['estimated_coverage'] = estimated_coverage
            
            # åˆ†æä¸åŒç±»å‹çš„æµ‹è¯•ç”¨ä¾‹
            normal_cases = len([tc for tc in test_cases if tc.boundary_type == 'normal'])
            boundary_cases = len([tc for tc in test_cases if tc.boundary_type == 'boundary'])
            edge_cases = len([tc for tc in test_cases if tc.boundary_type == 'edge_case'])
            
            coverage_analysis['coverage_details'] = {
                'normal_cases': normal_cases,
                'boundary_cases': boundary_cases,
                'edge_cases': edge_cases
            }
        
        return coverage_analysis
    
    def _build_test_generation_prompt(self, function_info: Dict[str, Any],
                                    example_cases: List[Dict[str, Any]],
                                    function_properties: Dict[str, Any]) -> str:
        """æ„å»ºæµ‹è¯•ç”¨ä¾‹ç”Ÿæˆprompt"""
        
        # ä¼˜å…ˆä½¿ç”¨promptç®¡ç†å™¨æ„å»ºprompt
        if self.prompt_manager:
            try:
                logger.info("ä½¿ç”¨promptç®¡ç†å™¨æ„å»ºæµ‹è¯•ç”¨ä¾‹ç”Ÿæˆprompt")
                return self.prompt_manager.format_single_function_test_prompt(
                    function_name=function_info.get('name', 'unknown'),
                    return_type=function_info.get('return_type', 'unknown'),
                    parameters=function_info.get('parameters', []),
                    function_body=function_info.get('body_content', ''),
                    function_properties=function_properties,
                    example_test_cases=example_cases
                )
            except Exception as e:
                logger.warning(f"ä½¿ç”¨promptç®¡ç†å™¨æ„å»ºpromptå¤±è´¥: {e}")
                logger.info("å›é€€åˆ°é»˜è®¤promptæ„å»ºé€»è¾‘")
        
        # å›é€€åˆ°åŸæ¥çš„promptæ„å»ºé€»è¾‘
        logger.info("ä½¿ç”¨é»˜è®¤promptæ„å»ºé€»è¾‘")
        prompt_lines = []
        prompt_lines.append("è¯·ä¸ºä»¥ä¸‹Cå‡½æ•°ç”Ÿæˆå…¨é¢çš„å•å…ƒæµ‹è¯•ç”¨ä¾‹ï¼š")
        prompt_lines.append("")
        
        # å‡½æ•°åŸºæœ¬ä¿¡æ¯
        prompt_lines.append("=== å‡½æ•°åŸºæœ¬ä¿¡æ¯ ===")
        prompt_lines.append(f"å‡½æ•°å: {function_info.get('name', 'unknown')}")
        prompt_lines.append(f"è¿”å›ç±»å‹: {function_info.get('return_type', 'unknown')}")
        prompt_lines.append(f"å‚æ•°: {self._format_parameters(function_info.get('parameters', []))}")
        prompt_lines.append(f"å‡½æ•°ä½“: {function_info.get('body_content', '')}")
        prompt_lines.append("")
        
        # å‡½æ•°å±æ€§ä¿¡æ¯
        if function_properties:
            prompt_lines.append("=== å‡½æ•°å±æ€§ä¿¡æ¯ ===")
            for key, value in function_properties.items():
                prompt_lines.append(f"{key}: {value}")
            prompt_lines.append("")
        
        # ç¤ºä¾‹æµ‹è¯•ç”¨ä¾‹
        if example_cases:
            prompt_lines.append("=== ç°æœ‰æµ‹è¯•ç”¨ä¾‹ç¤ºä¾‹ ===")
            for i, case in enumerate(example_cases, 1):
                prompt_lines.append(f"ç¤ºä¾‹{i}:")
                prompt_lines.append(f"  æµ‹è¯•ç”¨ä¾‹åç§°: {case['test_case_name']}")
                prompt_lines.append(f"  è¾“å…¥å€¼: {case['input_values']}")
                prompt_lines.append(f"  æœŸæœ›è¾“å‡º: {case['expected_output']}")
                prompt_lines.append(f"  æµ‹è¯•ç±»å‹: {case['test_type']}")
                prompt_lines.append(f"  æè¿°: {case['description']}")
                prompt_lines.append("")
        
        # ç”Ÿæˆè¦æ±‚
        prompt_lines.append("=== ç”Ÿæˆè¦æ±‚ ===")
        prompt_lines.append("è¯·ç”Ÿæˆä»¥ä¸‹ç±»å‹çš„æµ‹è¯•ç”¨ä¾‹ï¼š")
        prompt_lines.append("1. æ­£å¸¸æƒ…å†µæµ‹è¯•ç”¨ä¾‹ï¼ˆnormalï¼‰")
        prompt_lines.append("2. è¾¹ç•Œå€¼æµ‹è¯•ç”¨ä¾‹ï¼ˆboundaryï¼‰")
        prompt_lines.append("3. å¼‚å¸¸æƒ…å†µæµ‹è¯•ç”¨ä¾‹ï¼ˆedge_caseï¼‰")
        prompt_lines.append("")
        prompt_lines.append("è¯·å‚è€ƒç°æœ‰ç¤ºä¾‹ï¼Œç”Ÿæˆæ›´å¤šæ ·åŒ–å’Œå…¨é¢çš„æµ‹è¯•ç”¨ä¾‹ã€‚")
        prompt_lines.append("è¯·ä»¥JSONæ ¼å¼è¿”å›ï¼Œæ ¼å¼å¦‚ä¸‹ï¼š")
        prompt_lines.append("""
            {
                "test_cases": [
                    {
                        "test_name": "æµ‹è¯•ç”¨ä¾‹åç§°",
                        "input_values": {"å‚æ•°å": "å‚æ•°å€¼"},
                        "expected_output": "æœŸæœ›è¾“å‡º",
                        "description": "æµ‹è¯•æè¿°",
                        "boundary_type": "normal/boundary/edge_case"
                    }
                ]
            }
        """)
        
        return "\n".join(prompt_lines)
    
    def _format_parameters(self, parameters: List[Dict]) -> str:
        """æ ¼å¼åŒ–å‡½æ•°å‚æ•°"""
        if not parameters:
            return "æ— å‚æ•°"
        
        param_strs = []
        for param in parameters:
            param_type = param.get('type', 'unknown')
            param_name = param.get('name', 'unnamed')
            param_strs.append(f"{param_type} {param_name}")
        
        return ', '.join(param_strs)
    
    def _parse_test_cases_response(self, response: str, function_info: Dict[str, Any]) -> List[TestCase]:
        """è§£æå¤§æ¨¡å‹å“åº”ç”Ÿæˆæµ‹è¯•ç”¨ä¾‹"""
        test_cases = []
        
        try:
            # å°è¯•æå–JSONéƒ¨åˆ†
            import re
            json_match = re.search(r'\{.*\}', response, re.DOTALL)
            if json_match:
                data = json.loads(json_match.group())
                for i, tc_data in enumerate(data.get('test_cases', []), 1):
                    print("ç¬¬", i, "ä¸ªæµ‹è¯•ç”¨ä¾‹")
                    test_case = TestCase(
                        test_id=f"{function_info.get('name', 'unknown')}_TC_{i:03d}",
                        test_name=tc_data.get('test_name', f'Generated_Test_{i}'),
                        input_values=tc_data.get('input_values', {}),
                        expected_output=tc_data.get('expected_output', ''),
                        description=tc_data.get('description', ''),
                        boundary_type=tc_data.get('boundary_type', 'normal'),
                        coverage_target=tc_data.get('coverage_target', ''),
                        priority=tc_data.get('priority', ''),
                    )
                    test_cases.append(test_case)
                logger.info(f"æˆåŠŸè§£æ {len(test_cases)} ä¸ªæµ‹è¯•ç”¨ä¾‹")
            else:
                logger.warning("å“åº”ä¸­æ²¡æœ‰æ‰¾åˆ°æœ‰æ•ˆçš„JSONæ ¼å¼")
        except Exception as e:
            logger.error(f"è§£ææµ‹è¯•ç”¨ä¾‹å“åº”æ—¶å‡ºé”™: {e}")
        
        return test_cases
    
    def _extract_response_content(self, response) -> str:
        """æå–å“åº”å†…å®¹ï¼Œæ”¯æŒå¤šç§å“åº”æ ¼å¼"""
        try:
            logger.info(f"å“åº”ç±»å‹: {type(response)}")
            
            # å°è¯•ä¸åŒçš„å“åº”æ ¼å¼
            if hasattr(response, 'content'):
                # æ ‡å‡†LangChainæ ¼å¼
                content = response.content
                logger.info(f"ä½¿ç”¨contentå±æ€§ï¼Œå†…å®¹é•¿åº¦: {len(content)}")
                return content
            elif hasattr(response, 'text'):
                # æŸäº›LLMå®¢æˆ·ç«¯ä½¿ç”¨textå±æ€§
                text = response.text
                logger.info(f"ä½¿ç”¨textå±æ€§ï¼Œå†…å®¹é•¿åº¦: {len(text)}")
                return text
            elif hasattr(response, 'message'):
                # æŸäº›å®¢æˆ·ç«¯ä½¿ç”¨messageå±æ€§
                if hasattr(response.message, 'content'):
                    content = response.message.content
                    logger.info(f"ä½¿ç”¨message.contentå±æ€§ï¼Œå†…å®¹é•¿åº¦: {len(content)}")
                    return content
                else:
                    message = str(response.message)
                    logger.info(f"ä½¿ç”¨messageå±æ€§ï¼Œå†…å®¹é•¿åº¦: {len(message)}")
                    return message
            elif hasattr(response, 'choices') and len(response.choices) > 0:
                # OpenAIæ ¼å¼
                content = response.choices[0].message.content
                logger.info(f"ä½¿ç”¨choicesæ ¼å¼ï¼Œå†…å®¹é•¿åº¦: {len(content)}")
                return content
            elif isinstance(response, dict):
                # JSONæ ¼å¼å“åº”
                logger.info(f"å“åº”æ˜¯å­—å…¸æ ¼å¼: {list(response.keys())}")
                if 'content' in response:
                    return response['content']
                elif 'text' in response:
                    return response['text']
                elif 'message' in response:
                    return response['message']
                elif 'response' in response:
                    return response['response']
                elif 'result' in response:
                    return response['result']
                else:
                    logger.warning(f"å­—å…¸å“åº”ä¸­æ²¡æœ‰æ‰¾åˆ°å†…å®¹å­—æ®µï¼Œè¿”å›æ•´ä¸ªå“åº”")
                    return str(response)
            elif isinstance(response, str):
                # ç›´æ¥å­—ç¬¦ä¸²å“åº”
                logger.info(f"å“åº”æ˜¯å­—ç¬¦ä¸²æ ¼å¼ï¼Œé•¿åº¦: {len(response)}")
                return response
            else:
                # å…¶ä»–æ ¼å¼ï¼Œè½¬æ¢ä¸ºå­—ç¬¦ä¸²
                logger.warning(f"æœªçŸ¥çš„å“åº”æ ¼å¼: {type(response)}")
                logger.info(f"å“åº”å†…å®¹: {response}")
                return str(response)
                
        except Exception as e:
            logger.error(f"æå–å“åº”å†…å®¹æ—¶å‡ºé”™: {e}")
            logger.info(f"åŸå§‹å“åº”: {response}")
            return str(response)
    
    def _generate_mock_test_cases(self, function_info: Dict[str, Any]) -> List[TestCase]:
        """ç”Ÿæˆæ¨¡æ‹Ÿæµ‹è¯•ç”¨ä¾‹ï¼ˆå½“LLMä¸å¯ç”¨æ—¶ä½¿ç”¨ï¼‰"""
        logger.info("ç”Ÿæˆæ¨¡æ‹Ÿæµ‹è¯•ç”¨ä¾‹")
        
        function_name = function_info.get('name', 'unknown')
        parameters = function_info.get('parameters', [])
        branch_info = function_info.get('branch_info', {})
        
        test_cases = []
        
        # æ ¹æ®å‡½æ•°åç”Ÿæˆä¸åŒçš„æµ‹è¯•ç”¨ä¾‹
        if function_name == 'is_value_in_range':
            # ä¸º is_value_in_range å‡½æ•°ç”Ÿæˆæµ‹è¯•ç”¨ä¾‹
            test_cases = [
                TestCase(
                    test_name="æ­£å¸¸èŒƒå›´æµ‹è¯•",
                    input_values={"value": 5, "min": 1, "max": 10},
                    expected_output=1,
                    description="æµ‹è¯•å€¼åœ¨æ­£å¸¸èŒƒå›´å†…çš„æƒ…å†µ",
                    boundary_type="normal",
                    test_id=f"{function_name}_TC_001"
                ),
                TestCase(
                    test_name="è¾¹ç•Œå€¼æµ‹è¯•-æœ€å°å€¼",
                    input_values={"value": 1, "min": 1, "max": 10},
                    expected_output=1,
                    description="æµ‹è¯•å€¼ç­‰äºæœ€å°å€¼çš„æƒ…å†µ",
                    boundary_type="boundary",
                    test_id=f"{function_name}_TC_002"
                ),
                TestCase(
                    test_name="è¾¹ç•Œå€¼æµ‹è¯•-æœ€å¤§å€¼",
                    input_values={"value": 10, "min": 1, "max": 10},
                    expected_output=1,
                    description="æµ‹è¯•å€¼ç­‰äºæœ€å¤§å€¼çš„æƒ…å†µ",
                    boundary_type="boundary",
                    test_id=f"{function_name}_TC_003"
                ),
                TestCase(
                    test_name="è¶…å‡ºèŒƒå›´æµ‹è¯•-å°äºæœ€å°å€¼",
                    input_values={"value": 0, "min": 1, "max": 10},
                    expected_output=0,
                    description="æµ‹è¯•å€¼å°äºæœ€å°å€¼çš„æƒ…å†µ",
                    boundary_type="edge_case",
                    test_id=f"{function_name}_TC_004"
                ),
                TestCase(
                    test_name="è¶…å‡ºèŒƒå›´æµ‹è¯•-å¤§äºæœ€å¤§å€¼",
                    input_values={"value": 11, "min": 1, "max": 10},
                    expected_output=0,
                    description="æµ‹è¯•å€¼å¤§äºæœ€å¤§å€¼çš„æƒ…å†µ",
                    boundary_type="edge_case",
                    test_id=f"{function_name}_TC_005"
                )
            ]
        else:
            # ä¸ºå…¶ä»–å‡½æ•°ç”Ÿæˆé€šç”¨æµ‹è¯•ç”¨ä¾‹
            for i in range(3):
                test_case = TestCase(
                    test_name=f"æµ‹è¯•ç”¨ä¾‹_{i+1}",
                    input_values={param.get('name', f'param_{i}'): i for param in parameters},
                    expected_output=i,
                    description=f"é€šç”¨æµ‹è¯•ç”¨ä¾‹ {i+1}",
                    boundary_type="normal" if i == 0 else "boundary" if i == 1 else "edge_case",
                    test_id=f"{function_name}_TC_{i+1:03d}"
                )
                test_cases.append(test_case)
        
        logger.info(f"ç”Ÿæˆäº† {len(test_cases)} ä¸ªæ¨¡æ‹Ÿæµ‹è¯•ç”¨ä¾‹")
        return test_cases

class ExcelUpdater:
    """Excelæ–‡ä»¶æ›´æ–°å™¨"""
    
    def __init__(self):
        self.properties_sheet = "Properties"
        self.values_sheet = "Values"
        self.description_field = "Description"
    
    def update_excel_with_test_cases(self, excel_path: str, test_cases: List[TestCase], 
                                   function_name: str, output_dir: str) -> str:
        """
        ç¬¬å…­æ­¥ï¼šæ›´æ–°Excelæ–‡ä»¶ï¼Œæ”¯æŒåŒè¡¨å¤´æ ¼å¼
        
        Args:
            excel_path: åŸå§‹Excelæ–‡ä»¶è·¯å¾„
            test_cases: ç”Ÿæˆçš„æµ‹è¯•ç”¨ä¾‹
            function_name: å‡½æ•°å
            output_dir: è¾“å‡ºç›®å½•
            
        Returns:
            æ›´æ–°åçš„Excelæ–‡ä»¶è·¯å¾„
        """
        logger.info(f"å¼€å§‹æ›´æ–°Excelæ–‡ä»¶: {excel_path}")
        
        try:
            # è¯»å–ç°æœ‰Excelæ–‡ä»¶
            excel_file = pd.ExcelFile(excel_path)
            
            # åªè¯»å–Propertieså’ŒValuesä¸¤ä¸ªå·¥ä½œè¡¨
            all_sheets = {}
            required_sheets = [self.properties_sheet, self.values_sheet]
            
            for sheet_name in excel_file.sheet_names:
             
                try:
                    # å°è¯•è¯»å–ä¸ºåŒè¡¨å¤´æ ¼å¼ï¼ˆä¸è®¾ç½®headerï¼‰
                    df = pd.read_excel(excel_path, sheet_name=sheet_name, header=None)
                    all_sheets[sheet_name] = df
                    logger.info(f"æˆåŠŸè¯»å–å·¥ä½œè¡¨: {sheet_name}")
                except Exception as e:
                    logger.warning(f"è¯»å–å·¥ä½œè¡¨ {sheet_name} æ—¶å‡ºé”™: {e}")
                    # åˆ›å»ºç©ºçš„å·¥ä½œè¡¨
                    all_sheets[sheet_name] = pd.DataFrame()
            
            # æ£€æŸ¥å¿…éœ€çš„å·¥ä½œè¡¨æ˜¯å¦å­˜åœ¨
            missing_sheets = []
            for sheet_name in required_sheets:
                if sheet_name not in all_sheets:
                    missing_sheets.append(sheet_name)
                    # åˆ›å»ºç©ºçš„å·¥ä½œè¡¨
                    all_sheets[sheet_name] = pd.DataFrame()
                    logger.warning(f"å·¥ä½œè¡¨ {sheet_name} ä¸å­˜åœ¨ï¼Œå°†åˆ›å»ºç©ºå·¥ä½œè¡¨")
            
            if missing_sheets:
                logger.warning(f"ç¼ºå°‘å¿…éœ€çš„å·¥ä½œè¡¨: {missing_sheets}")
            
            # æ›´æ–°Valueså·¥ä½œè¡¨
            if self.values_sheet in all_sheets:
                updated_values_df, case_step_list = self._update_values_sheet(
                    all_sheets[self.values_sheet], test_cases, function_name
                )
                all_sheets[self.values_sheet] = updated_values_df
                logger.info(f"å·²æ›´æ–°Valueså·¥ä½œè¡¨")
            else:
                logger.error(f"Valueså·¥ä½œè¡¨ä¸å­˜åœ¨ä¸”æ— æ³•åˆ›å»º")
            
            # æ›´æ–°Propertieså·¥ä½œè¡¨
            if self.properties_sheet in all_sheets:
                updated_properties_df = self._update_properties_sheet(
                    all_sheets[self.properties_sheet], test_cases, function_name, case_step_list
                )
                all_sheets[self.properties_sheet] = updated_properties_df
                logger.info(f"å·²æ›´æ–°Propertieså·¥ä½œè¡¨")
            else:
                logger.error(f"Propertieså·¥ä½œè¡¨ä¸å­˜åœ¨ä¸”æ— æ³•åˆ›å»º")
            
            # ä¿å­˜æ›´æ–°åçš„Excelæ–‡ä»¶
            output_path = self._save_updated_excel(excel_path, all_sheets, function_name, output_dir)
            
            logger.info(f"å·²æ›´æ–°Excelæ–‡ä»¶: {output_path}")
            return output_path
            
        except Exception as e:
            logger.error(f"æ›´æ–°Excelæ–‡ä»¶æ—¶å‡ºé”™: {e}")
            return excel_path
    
    def _update_values_sheet(self, values_df: pd.DataFrame, 
                           test_cases: List[TestCase], function_name: str) -> pd.DataFrame:
        """æ›´æ–°Valueså·¥ä½œè¡¨ï¼Œæ”¯æŒåŒè¡¨å¤´æ ¼å¼å¹¶ä¿æŒåŸæœ‰æ ¼å¼"""
        try:
            # æ£€æŸ¥æ˜¯å¦ä¸ºåŒè¡¨å¤´æ ¼å¼ï¼ˆè‡³å°‘æœ‰ä¸¤è¡Œæ•°æ®ï¼‰
            if len(values_df) >= 2:
                # ä¿ç•™å‰ä¸¤è¡Œä½œä¸ºè¡¨å¤´
                header_rows = values_df.iloc[:2].copy()
                
                case_num = 0
                step_num = 1
                case_step_list = []
                # åˆ›å»ºæ–°çš„æµ‹è¯•ç”¨ä¾‹æ•°æ®ï¼Œä»ç¬¬ä¸‰è¡Œå¼€å§‹
                new_test_cases = []
                for i, test_case in enumerate(test_cases, 1):
                    # æ„å»ºæµ‹è¯•ç”¨ä¾‹è¡Œï¼Œå¯¹åº”å‚æ•°åç§°
                    test_case_row = {}
                    
                    # ç¬¬ä¸€åˆ—ä¸ºæµ‹è¯•ç”¨ä¾‹ID
                    case_num = i
                    test_case_row[values_df.columns[0]] = f"tc{case_num}.{step_num}"
                    
                    case_step_list.append({"case_num": case_num, "step_num": step_num})
                    # æ ¹æ®å‚æ•°åç§°å¡«å……è¾“å…¥å€¼
                    param_names = header_rows.iloc[0].dropna().tolist()
                    io_types = header_rows.iloc[1].dropna().tolist()
                    
                    for j, (param_name, io_type) in enumerate(zip(param_names, io_types)):
                        if io_type.lower() == 'i':  # è¾“å…¥å‚æ•°
                            # ä»æµ‹è¯•ç”¨ä¾‹çš„è¾“å…¥å€¼ä¸­è·å–å¯¹åº”å‚æ•°çš„å€¼
                            input_value = test_case.input_values.get(param_name, '')
                            test_case_row[values_df.columns[j+1]] = input_value
                        elif io_type.lower() == 'o':  # è¾“å‡ºå‚æ•°
                            # ä½¿ç”¨æœŸæœ›è¾“å‡º
                            test_case_row[values_df.columns[j+1]] = test_case.expected_output
                    
                    new_test_cases.append(test_case_row)
                
                # åˆ›å»ºæ–°çš„DataFrame
                new_df = pd.DataFrame(new_test_cases)
                
                # åˆå¹¶æ•°æ®ï¼šä¿ç•™å‰ä¸¤è¡Œè¡¨å¤´ï¼Œæ·»åŠ æ–°çš„æµ‹è¯•ç”¨ä¾‹è¡Œ
                combined_df = pd.concat([header_rows, new_df], ignore_index=True)
                
                logger.info(f"Valueså·¥ä½œè¡¨å·²æ›´æ–°ï¼Œä¿æŒåŒè¡¨å¤´æ ¼å¼ï¼Œæ·»åŠ äº† {len(test_cases)} ä¸ªæµ‹è¯•ç”¨ä¾‹")
                return combined_df, case_step_list
            else:
                # å¦‚æœæ•°æ®ä¸è¶³ä¸¤è¡Œï¼Œä½¿ç”¨é»˜è®¤æ–¹æ³•
                logger.warning("Valueså·¥ä½œè¡¨æ ¼å¼ä¸ç¬¦åˆåŒè¡¨å¤´è¦æ±‚ï¼Œä½¿ç”¨é»˜è®¤æ›´æ–°æ–¹æ³•")
                return self._update_values_sheet_default(values_df, test_cases, function_name)
            
        except Exception as e:
            logger.error(f"æ›´æ–°Valueså·¥ä½œè¡¨æ—¶å‡ºé”™: {e}")
            return values_df
    
    def _update_values_sheet_default(self, values_df: pd.DataFrame, 
                                   test_cases: List[TestCase], function_name: str) -> pd.DataFrame:
        """é»˜è®¤çš„Valueså·¥ä½œè¡¨æ›´æ–°æ–¹æ³•"""
        try:
            # åˆ›å»ºæ–°çš„æµ‹è¯•ç”¨ä¾‹æ•°æ®
            new_test_cases = []
            
            for test_case in test_cases:
                test_case_row = {
                    'Test_Case_ID': test_case.test_id,
                    'Test_Case_Name': test_case.test_name,
                    'Function_Name': function_name,
                    'Input_Values': json.dumps(test_case.input_values, ensure_ascii=False),
                    'Expected_Output': str(test_case.expected_output),
                    'Test_Type': test_case.boundary_type,
                    'Description': test_case.description,
                    'Status': 'Generated',
                    'Created_Date': pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')
                }
                new_test_cases.append(test_case_row)
            
            # åˆ›å»ºæ–°çš„DataFrame
            new_df = pd.DataFrame(new_test_cases)
            
            # åˆå¹¶æ•°æ®
            if not values_df.empty:
                common_columns = list(set(values_df.columns) & set(new_df.columns))
                if common_columns:
                    combined_df = pd.concat([values_df[common_columns], new_df[common_columns]], 
                                          ignore_index=True)
                else:
                    combined_df = new_df
            else:
                combined_df = new_df
            
            logger.info(f"Valueså·¥ä½œè¡¨å·²æ›´æ–°ï¼Œæ·»åŠ äº† {len(test_cases)} ä¸ªæµ‹è¯•ç”¨ä¾‹")
            return combined_df
            
        except Exception as e:
            logger.error(f"æ›´æ–°Valueså·¥ä½œè¡¨æ—¶å‡ºé”™: {e}")
            return values_df
    
    def _update_properties_sheet(self, properties_df: pd.DataFrame, 
                               test_cases: List[TestCase], 
                               function_name: str, 
                               case_step_list: List[Dict[str, Any]]) -> pd.DataFrame:
        """æ›´æ–°Propertieså·¥ä½œè¡¨ï¼Œæ”¯æŒåŒè¡¨å¤´æ ¼å¼"""
        try:
            # æ£€æŸ¥æ˜¯å¦ä¸ºåŒè¡¨å¤´æ ¼å¼ï¼ˆè‡³å°‘æœ‰ä¸¤è¡Œæ•°æ®ï¼‰
            if len(properties_df) >= 2:
  
                # æ„å»ºæµ‹è¯•ç”¨ä¾‹æè¿°
                test_info, test_case_summary = self._build_test_case_summary(test_cases)
                
                # åˆ›å»ºæ–°è¡Œ
                if properties_df.iloc[3,4] == 'Description':
                    
                    # ç¡®ä¿DataFrameæœ‰è¶³å¤Ÿçš„è¡Œæ¥å®¹çº³æ–°çš„æµ‹è¯•ç”¨ä¾‹ä¿¡æ¯
                    required_rows = 4 + len(test_info)  # 4è¡Œè¡¨å¤´ + æµ‹è¯•ç”¨ä¾‹æ•°é‡
                    if len(properties_df) < required_rows:
                        # æ‰©å±•DataFrameçš„å¤§å°
                        additional_rows = required_rows - len(properties_df)
                        empty_rows = pd.DataFrame(index=range(additional_rows), columns=properties_df.columns)
                        properties_df = pd.concat([properties_df, empty_rows], ignore_index=True)
                        logger.info(f"æ‰©å±•Propertieså·¥ä½œè¡¨ï¼Œæ·»åŠ äº† {additional_rows} è¡Œ")
                    
                    # ç¡®ä¿æ–°è¡Œæœ‰æ‰€æœ‰å¿…è¦çš„åˆ—
                    for i, info_dict in enumerate(test_info):
                        
                        properties_df.iloc[4 + i, 0] = case_step_list[i]['case_num']
                        properties_df.iloc[4 + i, 1] = case_step_list[i]['step_num']
                        properties_df.iloc[4 + i, 4] = info_dict['description']
                
                logger.info(f"Propertieså·¥ä½œè¡¨å·²æ›´æ–°ï¼Œä¸ºå‡½æ•° {function_name} æ·»åŠ äº†æµ‹è¯•ç”¨ä¾‹æè¿°")
                return properties_df
            else:
                # å¦‚æœæ•°æ®ä¸è¶³ä¸¤è¡Œï¼Œä½¿ç”¨é»˜è®¤æ–¹æ³•
                logger.warning("Propertieså·¥ä½œè¡¨æ ¼å¼ä¸ç¬¦åˆåŒè¡¨å¤´è¦æ±‚ï¼Œä½¿ç”¨é»˜è®¤æ›´æ–°æ–¹æ³•")
                return self._update_properties_sheet_default(properties_df, test_cases, function_name)
            
        except Exception as e:
            logger.error(f"æ›´æ–°Propertieså·¥ä½œè¡¨æ—¶å‡ºé”™: {e}")
            return properties_df
    
    def _update_properties_sheet_default(self, properties_df: pd.DataFrame, 
                                       test_cases: List[TestCase], function_name: str) -> pd.DataFrame:
        """é»˜è®¤çš„Propertieså·¥ä½œè¡¨æ›´æ–°æ–¹æ³•"""
        try:
            # æŸ¥æ‰¾æˆ–åˆ›å»ºå‡½æ•°ç›¸å…³çš„å±æ€§è¡Œ
            function_row_index = None
            
            for i, row in properties_df.iterrows():
                if 'Function_Name' in row and row['Function_Name'] == function_name:
                    function_row_index = i
                    break
            
            # æ„å»ºæµ‹è¯•ç”¨ä¾‹æè¿°
            test_info, test_case_summary = self._build_test_case_summary(test_cases)
            
            if function_row_index is not None:
                # æ›´æ–°ç°æœ‰è¡Œ
                if 'Description' in properties_df.columns:
                    current_desc = str(properties_df.at[function_row_index, 'Description'])
                    new_desc = f"{current_desc}\n\n=== è‡ªåŠ¨ç”Ÿæˆçš„æµ‹è¯•ç”¨ä¾‹ ===\n{test_case_summary}"
                    properties_df.at[function_row_index, 'Description'] = new_desc
            else:
                # åˆ›å»ºæ–°è¡Œ
                new_row = {
                    'Function_Name': function_name,
                    'Description': f"=== è‡ªåŠ¨ç”Ÿæˆçš„æµ‹è¯•ç”¨ä¾‹ ===\n{test_case_summary}",
                    'Test_Case_Count': len(test_cases),
                    'Generated_Date': pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')
                }
                
                new_df = pd.DataFrame([new_row])
                properties_df = pd.concat([properties_df, new_df], ignore_index=True)
            
            logger.info(f"Propertieså·¥ä½œè¡¨å·²æ›´æ–°ï¼Œä¸ºå‡½æ•° {function_name} æ·»åŠ äº†æµ‹è¯•ç”¨ä¾‹æè¿°")
            return properties_df
            
        except Exception as e:
            logger.error(f"æ›´æ–°Propertieså·¥ä½œè¡¨æ—¶å‡ºé”™: {e}")
            return properties_df
    

    
    def _build_test_case_summary(self, test_cases: List[TestCase]) -> str:
        """æ„å»ºæµ‹è¯•ç”¨ä¾‹æ‘˜è¦ï¼ŒåŒ…å«test_idå’Œdescriptionçš„æå–ä¿¡æ¯"""
        summary_lines = []
        
        # ç»Ÿè®¡ä¿¡æ¯
        normal_count = len([tc for tc in test_cases if tc.boundary_type == 'normal'])
        boundary_count = len([tc for tc in test_cases if tc.boundary_type == 'boundary'])
        edge_count = len([tc for tc in test_cases if tc.boundary_type == 'edge_case'])
        
        summary_lines.append(f"æ€»æµ‹è¯•ç”¨ä¾‹æ•°: {len(test_cases)}")
        summary_lines.append(f"- æ­£å¸¸æµ‹è¯•ç”¨ä¾‹: {normal_count}")
        summary_lines.append(f"- è¾¹ç•Œæµ‹è¯•ç”¨ä¾‹: {boundary_count}")
        summary_lines.append(f"- å¼‚å¸¸æµ‹è¯•ç”¨ä¾‹: {edge_count}")
        summary_lines.append("")
        
        # æå–test_idå’Œdescriptionä¿¡æ¯
        test_info = []
        for test_case in test_cases:
            test_info.append({
                'description': test_case.description
            })
        
        # è®°å½•æå–çš„test_idå’Œdescriptionä¿¡æ¯
        summary_lines.append("=== æå–çš„æµ‹è¯•ç”¨ä¾‹ä¿¡æ¯ ===")
        summary_lines.append(f"æå–åˆ° {len(test_info)} ä¸ªæµ‹è¯•ç”¨ä¾‹çš„test_idå’Œdescription:")
        summary_lines.append("")
        
        for i, info in enumerate(test_info, 1):
            summary_lines.append(f"{i}. Test ID: {info['test_id']}")
            summary_lines.append(f"   Description: {info['description']}")
            summary_lines.append("")
        
        # æ˜¾ç¤ºåˆ—è¡¨æ ¼å¼çš„æå–ç»“æœ
        test_ids = [info['test_id'] for info in test_info]
        descriptions = [info['description'] for info in test_info]
        
        summary_lines.append("=== åˆ—è¡¨æ ¼å¼æå–ç»“æœ ===")
        summary_lines.append(f"Test IDs: {test_ids}")
        summary_lines.append(f"Descriptions: {descriptions}")
        summary_lines.append("")
        
        # è¯¦ç»†æµ‹è¯•ç”¨ä¾‹åˆ—è¡¨
        summary_lines.append("=== è¯¦ç»†æµ‹è¯•ç”¨ä¾‹åˆ—è¡¨ ===")
        for i, test_case in enumerate(test_cases, 1):
            summary_lines.append(f"{i}. {test_case.test_name} ({test_case.boundary_type})")
            summary_lines.append(f"   Test ID: {test_case.test_id}")
            summary_lines.append(f"   è¾“å…¥: {test_case.input_values}")
            summary_lines.append(f"   æœŸæœ›è¾“å‡º: {test_case.expected_output}")
            summary_lines.append(f"   æè¿°: {test_case.description}")
            if test_case.coverage_target:
                summary_lines.append(f"   è¦†ç›–ç›®æ ‡: {test_case.coverage_target}")
            if test_case.priority:
                summary_lines.append(f"   ä¼˜å…ˆçº§: {test_case.priority}")
            summary_lines.append("")
        
        return test_info, "\n".join(summary_lines)
    
    def _save_updated_excel(self, original_path: str, all_sheets: Dict[str, pd.DataFrame], 
                           function_name: str, output_dir: str) -> str:
        """ä¿å­˜æ›´æ–°åçš„Excelæ–‡ä»¶ï¼Œä¿å­˜æ‰€æœ‰å·¥ä½œè¡¨"""
        try:
            # ç”Ÿæˆæ–°çš„æ–‡ä»¶å
            original_path_obj = Path(original_path)
            timestamp = pd.Timestamp.now().strftime('%Y%m%d_%H%M%S')
            new_filename = f"{original_path_obj.stem}_{function_name}_{timestamp}.xlsx"
            output_path = Path(output_dir) / new_filename
            
            # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
            output_path.parent.mkdir(parents=True, exist_ok=True)
            
            # ä½¿ç”¨ExcelWriterä¿å­˜æ‰€æœ‰å·¥ä½œè¡¨
            with pd.ExcelWriter(output_path, engine='openpyxl') as writer:
                saved_sheets = 0
                skipped_sheets = 0
                
                for sheet_name, df in all_sheets.items():
                    if not df.empty:
                        # ä¿å­˜æ—¶ä¿æŒåŸæœ‰æ ¼å¼ï¼Œä¸è®¾ç½®ç´¢å¼•
                        df.to_excel(writer, sheet_name=sheet_name, index=False, header=False)
                        logger.info(f"å·²ä¿å­˜å·¥ä½œè¡¨: {sheet_name}ï¼Œä¿æŒåŸæœ‰æ ¼å¼")
                        saved_sheets += 1
                    else:
                        logger.warning(f"å·¥ä½œè¡¨ {sheet_name} ä¸ºç©ºï¼Œè·³è¿‡ä¿å­˜")
                        skipped_sheets += 1
                
                logger.info(f"ä¿å­˜å®Œæˆ: {saved_sheets} ä¸ªå·¥ä½œè¡¨å·²ä¿å­˜ï¼Œ{skipped_sheets} ä¸ªå·¥ä½œè¡¨è¢«è·³è¿‡")
            
            logger.info(f"å·²ä¿å­˜æ›´æ–°åçš„Excelæ–‡ä»¶: {output_path}")
            return str(output_path)
            
        except Exception as e:
            logger.error(f"ä¿å­˜Excelæ–‡ä»¶æ—¶å‡ºé”™: {e}")
            return original_path

class UnitTestGenerator:
    """å•å…ƒæµ‹è¯•ç”Ÿæˆå™¨ä¸»ç±»"""
    
    def __init__(self):
        self.file_matcher = FilePairMatcher()
        self.code_analyzer = CCodeAnalyzer()
        self.excel_processor = ExcelDataProcessor()
        self.test_generator = LLMTestGenerator()
        self.excel_updater = ExcelUpdater()
    
    def process_file_pair(self, base_name: str, code_dir: str, excel_dir: str, 
                         output_dir: str = "result") -> Dict[str, Any]:
        """
        å¤„ç†å•ä¸ªæ–‡ä»¶å¯¹
        
        Args:
            base_name: åŸºç¡€æ–‡ä»¶å
            code_dir: Cä»£ç ç›®å½•
            excel_dir: Excelæ–‡ä»¶ç›®å½•
            output_dir: è¾“å‡ºç›®å½•
            
        Returns:
            å¤„ç†ç»“æœå­—å…¸
        """
        logger.info(f"å¼€å§‹å¤„ç†æ–‡ä»¶å¯¹: {base_name}")
        
        result = {
            'base_name': base_name,
            'success': False,
            'c_file_path': None,
            'excel_file_path': None,
            'analysis_result': {},
            'excel_data': {},
            'updated_excel_path': None,
            'error': None
        }
        
        try:
            # ç¬¬ä¸€æ­¥ï¼šåŒ¹é…æ–‡ä»¶å¯¹
            c_file_path, excel_file_path = self.file_matcher.find_matching_files(
                base_name, code_dir, excel_dir
            )
            
            if not c_file_path:
                result['error'] = "æ‰¾ä¸åˆ°Cæ–‡ä»¶"
                return result
            
            result['c_file_path'] = c_file_path
            result['excel_file_path'] = excel_file_path
            
            # ç¬¬äºŒæ­¥ï¼šè§£æCæ–‡ä»¶
            analysis_result = self.code_analyzer.analyze_file(c_file_path, output_dir)
            if not analysis_result:
                result['error'] = "Cæ–‡ä»¶è§£æå¤±è´¥"
                return result
            
            result['analysis_result'] = analysis_result
            
            # å¤„ç†æ¯ä¸ªå‡½æ•°
            functions = analysis_result.get('functions', [])
            all_test_cases = []
            
            for function_info in functions:
                function_name = function_info.get('name', 'unknown')
                logger.info(f"å¤„ç†å‡½æ•°: {function_name}")
                
                # ç”Ÿæˆæµ‹è¯•ç”¨ä¾‹
                test_cases = self.test_generator.generate_test_cases(
                    function_info
                )
                
                all_test_cases.extend(test_cases)
            
            result['test_cases'] = all_test_cases
            
            # ç¬¬å…­æ­¥ï¼šæ›´æ–°Excelæ–‡ä»¶
            if excel_file_path and all_test_cases:
                updated_excel_path = self.excel_updater.update_excel_with_test_cases(
                    excel_file_path, all_test_cases, functions[0].get('name', 'unknown'), output_dir
                )
                result['updated_excel_path'] = updated_excel_path
            
            result['success'] = True
            logger.info(f"æ–‡ä»¶å¯¹å¤„ç†å®Œæˆ: {base_name}")
            
        except Exception as e:
            result['error'] = str(e)
            logger.error(f"å¤„ç†æ–‡ä»¶å¯¹æ—¶å‡ºé”™: {e}")
        
        return result
    
    def process_folder_pair(self, code_folder: str, excel_folder: str, 
                          output_dir: str = "result") -> Dict[str, Any]:
        """
        å¤„ç†æ–‡ä»¶å¤¹å¯¹ï¼ŒæŒ‰ç…§æ–°çš„å…­æ­¥æµç¨‹
        
        Args:
            code_folder: Cä»£ç æ–‡ä»¶å¤¹è·¯å¾„
            excel_folder: Excelæ–‡ä»¶å¤¹è·¯å¾„
            output_dir: è¾“å‡ºç›®å½•
            
        Returns:
            å¤„ç†ç»“æœå­—å…¸
        """
        logger.info(f"å¼€å§‹å¤„ç†æ–‡ä»¶å¤¹å¯¹:")
        logger.info(f"  Cä»£ç æ–‡ä»¶å¤¹: {code_folder}")
        logger.info(f"  Excelæ–‡ä»¶å¤¹: {excel_folder}")
        
        result = {
            'folder_name': Path(code_folder).name,
            'success': False,
            'file_results': [],
            'total_test_cases': 0,
            'total_files_processed': 0,
            'error': None
        }
        
        try:
            # ç¬¬ä¸€æ­¥ï¼šè§£ææ–‡ä»¶å¤¹ä¸‹çš„æ‰€æœ‰Cå’ŒHæ–‡ä»¶
            logger.info("=== ç¬¬ä¸€æ­¥ï¼šè§£æCä»£ç æ–‡ä»¶ ===")
            analysis_result = self.code_analyzer.analyze_folder(code_folder, output_dir)
            if not analysis_result:
                result['error'] = "Cä»£ç æ–‡ä»¶å¤¹è§£æå¤±è´¥"
                return result
            
            logger.info(f"æˆåŠŸè§£ææ–‡ä»¶å¤¹ï¼Œå‘ç° {analysis_result.get('total_functions', 0)} ä¸ªå‡½æ•°")
            
            # æŸ¥æ‰¾æ–‡ä»¶å¤¹ä¸­çš„æ‰€æœ‰Excelæ–‡ä»¶
            excel_files = list(Path(excel_folder).glob("*.xlsx"))
            if not excel_files:
                result['error'] = "åœ¨Excelæ–‡ä»¶å¤¹ä¸­æ‰¾ä¸åˆ°Excelæ–‡ä»¶"
                return result
            
            logger.info(f"æ‰¾åˆ° {len(excel_files)} ä¸ªExcelæ–‡ä»¶")
            
            # å¤„ç†æ¯ä¸ªExcelæ–‡ä»¶
            for excel_file in excel_files:
                logger.info(f"å¤„ç†Excelæ–‡ä»¶: {excel_file.name}")
                
                file_result = {
                    'excel_file': str(excel_file),
                    'success': False,
                    'test_cases': [],
                    'updated_excel_path': None,
                    'error': None
                }
                
                try:
                    
                    # ç¬¬ä¸‰æ­¥ï¼šåˆå§‹åŒ–å¤§æ¨¡å‹
                    logger.info("=== ç¬¬ä¸‰æ­¥ï¼šåˆå§‹åŒ–å¤§æ¨¡å‹ ===")
                    if not self.test_generator.llm_available:
                        file_result['error'] = "å¤§æ¨¡å‹ä¸å¯ç”¨"
                        result['file_results'].append(file_result)
                        continue
                    
                    # ç¬¬å››æ­¥ï¼šæ„å»ºprompt
                    logger.info("=== ç¬¬å››æ­¥ï¼šæ„å»ºprompt ===")
                    # è¿™ä¸€æ­¥åœ¨generate_test_casesä¸­å®Œæˆ
                    
                    # å¤„ç†æ¯ä¸ªå‡½æ•°
                    functions = analysis_result.get('functions', [])
                    all_test_cases = []
                    
                    for function_info in functions:
                        function_name = function_info.get('name', 'unknown')
                        logger.info(f"å¤„ç†å‡½æ•°: {function_name}")
                        
                        # ç¬¬äº”æ­¥ï¼šç”Ÿæˆæµ‹è¯•ç”¨ä¾‹
                        logger.info("=== ç¬¬äº”æ­¥ï¼šç”Ÿæˆæµ‹è¯•ç”¨ä¾‹ ===")
                        test_cases = self.test_generator.generate_test_cases(
                            function_info
                        )
                        
                        all_test_cases.extend(test_cases)
                    
                    file_result['test_cases'] = all_test_cases
                    result['total_test_cases'] += len(all_test_cases)
                    
                    # ç¬¬å…­æ­¥ï¼šæ›´æ–°Excelæ–‡ä»¶
                    logger.info("=== ç¬¬å…­æ­¥ï¼šæ›´æ–°Excelæ–‡ä»¶ ===")
                    if all_test_cases:
                        updated_excel_path = self.excel_updater.update_excel_with_test_cases(
                            str(excel_file), all_test_cases, functions[0].get('name', 'unknown'), output_dir
                        )
                        file_result['updated_excel_path'] = updated_excel_path
                    
                    file_result['success'] = True
                    result['total_files_processed'] += 1
                    
                except Exception as e:
                    file_result['error'] = str(e)
                    logger.error(f"å¤„ç†Excelæ–‡ä»¶ {excel_file.name} æ—¶å‡ºé”™: {e}")
                
                result['file_results'].append(file_result)
            
            result['success'] = True
            logger.info(f"æ–‡ä»¶å¤¹å¯¹å¤„ç†å®Œæˆï¼ŒæˆåŠŸå¤„ç† {result['total_files_processed']} ä¸ªæ–‡ä»¶ï¼Œç”Ÿæˆ {result['total_test_cases']} ä¸ªæµ‹è¯•ç”¨ä¾‹")
            
        except Exception as e:
            result['error'] = str(e)
            logger.error(f"å¤„ç†æ–‡ä»¶å¤¹å¯¹æ—¶å‡ºé”™: {e}")
        
        return result
    
    def process_all_folders(self, code_dir: str, excel_dir: str, 
                           output_dir: str = "result") -> Dict[str, Any]:
        """
        å¤„ç†æ‰€æœ‰æ–‡ä»¶å¤¹å¯¹
        
        Args:
            code_dir: Cä»£ç æ ¹ç›®å½•
            excel_dir: Excelæ–‡ä»¶æ ¹ç›®å½•
            output_dir: è¾“å‡ºç›®å½•
            
        Returns:
            å¤„ç†ç»“æœå­—å…¸
        """
        logger.info(f"å¼€å§‹å¤„ç†æ‰€æœ‰æ–‡ä»¶å¤¹å¯¹:")
        logger.info(f"  Cä»£ç æ ¹ç›®å½•: {code_dir}")
        logger.info(f"  Excelæ ¹ç›®å½•: {excel_dir}")
        
        result = {
            'success': False,
            'folder_results': [],
            'total_folders_processed': 0,
            'total_files_processed': 0,
            'total_test_cases': 0,
            'error': None
        }
        
        try:
            # æŸ¥æ‰¾æ‰€æœ‰æ–‡ä»¶å¤¹å¯¹
            folder_pairs = self.file_matcher.find_folder_pairs(code_dir, excel_dir)
            
            if not folder_pairs:
                result['error'] = "æ‰¾ä¸åˆ°åŒ¹é…çš„æ–‡ä»¶å¤¹å¯¹"
                return result
            
            logger.info(f"æ‰¾åˆ° {len(folder_pairs)} ä¸ªæ–‡ä»¶å¤¹å¯¹")
            
            # å¤„ç†æ¯ä¸ªæ–‡ä»¶å¤¹å¯¹
            for folder_name, code_folder, excel_folder in folder_pairs:
                logger.info(f"å¤„ç†æ–‡ä»¶å¤¹å¯¹: {folder_name}")
                
                folder_result = self.process_folder_pair(code_folder, excel_folder, output_dir)
                result['folder_results'].append(folder_result)
                
                if folder_result['success']:
                    result['total_folders_processed'] += 1
                    result['total_files_processed'] += folder_result['total_files_processed']
                    result['total_test_cases'] += folder_result['total_test_cases']
            
            result['success'] = True
            logger.info(f"æ‰€æœ‰æ–‡ä»¶å¤¹å¯¹å¤„ç†å®Œæˆï¼ŒæˆåŠŸå¤„ç† {result['total_folders_processed']} ä¸ªæ–‡ä»¶å¤¹ï¼Œ{result['total_files_processed']} ä¸ªæ–‡ä»¶ï¼Œç”Ÿæˆ {result['total_test_cases']} ä¸ªæµ‹è¯•ç”¨ä¾‹")
            
        except Exception as e:
            result['error'] = str(e)
            logger.error(f"å¤„ç†æ‰€æœ‰æ–‡ä»¶å¤¹å¯¹æ—¶å‡ºé”™: {e}")
        
        return result

def main():
    """ä¸»å‡½æ•°"""

    file_mode="is_val_in_range"
    folder_mode="is_val_in_range"

    # è·å–å½“å‰è„šæœ¬æ‰€åœ¨ç›®å½•
    script_dir = Path(__file__).parent
    
    code_dir=str(script_dir / "code/is_val_in_range")
    excel_dir=str(script_dir / "context/is_val_in_range")
    output_dir=str(script_dir / "result/is_val_in_range")

    import argparse
    
    parser = argparse.ArgumentParser(description="å•å…ƒæµ‹è¯•ç”Ÿæˆå™¨")
    parser.add_argument("--mode", choices=["file", "folder", "all"], default="file", 
                       help="å¤„ç†æ¨¡å¼: file(å•ä¸ªæ–‡ä»¶å¯¹), folder(æ–‡ä»¶å¤¹å¯¹), all(æ‰€æœ‰æ–‡ä»¶å¤¹)")
    parser.add_argument("--base-name", help="åŸºç¡€æ–‡ä»¶åï¼ˆä¸å«æ‰©å±•åï¼‰ï¼Œä»…åœ¨fileæ¨¡å¼ä¸‹ä½¿ç”¨", default=file_mode)
    parser.add_argument("--code-dir", default=code_dir, help="Cä»£ç ç›®å½•")
    parser.add_argument("--excel-dir", default=excel_dir, help="Excelæ–‡ä»¶ç›®å½•")
    parser.add_argument("--output-dir", default=output_dir, help="è¾“å‡ºç›®å½•")
    parser.add_argument("--folder-name", help="æ–‡ä»¶å¤¹åç§°ï¼Œä»…åœ¨folderæ¨¡å¼ä¸‹ä½¿ç”¨", default=folder_mode)
    
    args = parser.parse_args()
    
    # åˆ›å»ºç”Ÿæˆå™¨
    generator = UnitTestGenerator()
    
    if args.mode == "file":
        # å¤„ç†å•ä¸ªæ–‡ä»¶å¯¹
        if not args.base_name:
            print("âŒ é”™è¯¯: fileæ¨¡å¼ä¸‹å¿…é¡»æŒ‡å®š--base-nameå‚æ•°")
            return
        
        result = generator.process_file_pair(
            args.base_name, args.code_dir, args.excel_dir, args.output_dir
        )
        
        # è¾“å‡ºç»“æœ
        if result['success']:
            print(f"âœ… å¤„ç†æˆåŠŸ: {args.base_name}")
            print(f"  ç”Ÿæˆçš„æµ‹è¯•ç”¨ä¾‹æ•°: {len(result['test_cases'])}")
            if result['updated_excel_path']:
                print(f"  æ›´æ–°çš„Excelæ–‡ä»¶: {result['updated_excel_path']}")
        else:
            print(f"âŒ å¤„ç†å¤±è´¥: {args.base_name}")
            print(f"  é”™è¯¯: {result['error']}")
    
    elif args.mode == "folder":
        # å¤„ç†æ–‡ä»¶å¤¹å¯¹
        if args.folder_name:
            # æŒ‡å®šæ–‡ä»¶å¤¹åç§°
            code_folder = Path(args.code_dir) / args.folder_name
            excel_folder = Path(args.excel_dir) / args.folder_name
            
            if not code_folder.exists():
                print(f"âŒ é”™è¯¯: Cä»£ç æ–‡ä»¶å¤¹ä¸å­˜åœ¨: {code_folder}")
                return
            
            if not excel_folder.exists():
                print(f"âŒ é”™è¯¯: Excelæ–‡ä»¶å¤¹ä¸å­˜åœ¨: {excel_folder}")
                return
            
            result = generator.process_folder_pair(
                str(code_folder), str(excel_folder), args.output_dir
            )
        else:
            # è‡ªåŠ¨æŸ¥æ‰¾æ–‡ä»¶å¤¹å¯¹
            folder_pairs = generator.file_matcher.find_folder_pairs(args.code_dir, args.excel_dir)
            if not folder_pairs:
                print("âŒ é”™è¯¯: æ‰¾ä¸åˆ°åŒ¹é…çš„æ–‡ä»¶å¤¹å¯¹")
                return
            
            if len(folder_pairs) == 1:
                # åªæœ‰ä¸€ä¸ªæ–‡ä»¶å¤¹å¯¹ï¼Œè‡ªåŠ¨å¤„ç†
                folder_name, code_folder, excel_folder = folder_pairs[0]
                print(f"è‡ªåŠ¨å¤„ç†æ–‡ä»¶å¤¹å¯¹: {folder_name}")
                result = generator.process_folder_pair(code_folder, excel_folder, args.output_dir)
            else:
                # å¤šä¸ªæ–‡ä»¶å¤¹å¯¹ï¼Œéœ€è¦ç”¨æˆ·é€‰æ‹©
                print("æ‰¾åˆ°å¤šä¸ªæ–‡ä»¶å¤¹å¯¹:")
                for i, (folder_name, _, _) in enumerate(folder_pairs, 1):
                    print(f"  {i}. {folder_name}")
                print("è¯·ä½¿ç”¨ --folder-name å‚æ•°æŒ‡å®šè¦å¤„ç†çš„æ–‡ä»¶å¤¹")
                return
        
        # è¾“å‡ºç»“æœ
        if result['success']:
            print(f"âœ… æ–‡ä»¶å¤¹å¤„ç†æˆåŠŸ: {result['folder_name']}")
            print(f"  å¤„ç†çš„æ–‡ä»¶æ•°: {result['total_files_processed']}")
            print(f"  ç”Ÿæˆçš„æµ‹è¯•ç”¨ä¾‹æ•°: {result['total_test_cases']}")
        else:
            print(f"âŒ æ–‡ä»¶å¤¹å¤„ç†å¤±è´¥: {result.get('folder_name', 'unknown')}")
            print(f"  é”™è¯¯: {result['error']}")
    
    elif args.mode == "all":
        # å¤„ç†æ‰€æœ‰æ–‡ä»¶å¤¹å¯¹
        result = generator.process_all_folders(args.code_dir, args.excel_dir, args.output_dir)
        
        # è¾“å‡ºç»“æœ
        if result['success']:
            print(f"âœ… æ‰€æœ‰æ–‡ä»¶å¤¹å¤„ç†æˆåŠŸ")
            print(f"  å¤„ç†çš„æ–‡ä»¶å¤¹æ•°: {result['total_folders_processed']}")
            print(f"  å¤„ç†çš„æ–‡ä»¶æ•°: {result['total_files_processed']}")
            print(f"  ç”Ÿæˆçš„æµ‹è¯•ç”¨ä¾‹æ•°: {result['total_test_cases']}")
        else:
            print(f"âŒ æ‰€æœ‰æ–‡ä»¶å¤¹å¤„ç†å¤±è´¥")
            print(f"  é”™è¯¯: {result['error']}")

if __name__ == "__main__":
    main() 